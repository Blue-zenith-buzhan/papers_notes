# Voice Jailbreak Attacks Against GPT-4o

```
https://doi.org/10.48550/arXiv.2405.19103
```

本文先是提出了一种猜想，即GPT-4o所引入的音频模式可能会带来新的攻击面。随后用六个被GPT-4o定义为敏感内容的问题集在没有越狱提示下通过语音形式进行攻击，得到攻击的平均成功率为0.233，接着在有越狱提示下对其进行语音形式的攻击，得到平均成功率为0.033。

因此作者总结出文本形式的越狱提示直接转为语音带来的效果很差，并提出了以下两个可能原因的猜想：

- 语音越狱提示的输入并不是一瞬间的，不像文本越狱提示，作者所用的越狱提示平均说话时间为171秒，时间较长，可能会带来不稳定因素
- GPT-4o在处理语音输入时是实时的，不是文本输入的直接处理，因此在句子之间的停顿可能会触发GPT-4o的响应

接着，作者进行尝试发现在通过语音输入文本形式的越狱提示时不管是禁忌问题还是普通问题，GPT-4o总会拒绝回答，因此作者认为GPT-4o的语音模式中已实施了一种未公开的保护措施来阻止越狱尝试，这可能和人们的白话形式与书面形式说的话的措辞等的不同有关。*（这部分仅为作者猜想，个人感觉原因可以不止或者不是这些）*

然后作者提出了在语音输入模式下的一种进行越狱攻击的方法。

先设定故事背景、人物、情节，通常如下：

- 背景：故事发生的世界观，为任何不同于现实世界的虚构场景，如游戏、剧本等，斌强调虚构性、剧情的无害性。
- 人物：主要用于推动剧情发展，可以是任何生物或者类人的虚拟非生物。
- 情节：故事从头到尾的发展，把禁忌问题引入情节作为称述虚拟人物的行为。

按照以上方法进行语音越狱攻击时分多次输入可以提高成功率。*（个人认为可能是可以模拟真实对话场景）*

基于以上的基础越狱框架，作者提出了一些高级技巧：

- Point of View（POV）：故事视角，一般以第一人称和第三人称为主。*（为什么不能用第二人称呢？个人感觉或许是因为第二人称可能存在一些教唆的意味）*在攻击中作者推荐使用第三人称以制造抽离感来规避安全检查。
- Red Herring*（直译为红鲱鱼，但这个词组是一个俚语，因此应该不能这么翻译）*：转移注意力的话，用于误导大模型了解攻击者的真实目的。
- Foreshadowing*（直译为预兆，个人感觉这里应该是埋下伏笔之意）*：通过当前的情节给出后续情节的提示，铺垫未来剧情，预示后续发展，接着一步步将大模型引入陷阱。

最后作者实验得出单次语音越狱攻击的输入的平均成功率为0.133，分多次为0.733，且想要效果好，基础的三要素缺一不可。

*这篇文章提出了一种语音模式下的越狱攻击方法，总体来看确实是这么个东西，但是文中的一些东西很多都停留于猜想层面，作者都未证实，而且这些猜想个人感觉还不足以使人信服。再者作者的实验是手动进行的近1k次的语音对话，目前个人不太了解这个数据量应该算多算少，总感觉这个局限性还是有点大的。另外作者提出的方法应该在文本状态下也是适用的（这个个人没证实过，只是感觉），不一定要用语音的方法，可能作者只是因为在语音和文本状态下的越狱攻击差别较大所以探索出了目前在语音模式下比较可行的方法。*
