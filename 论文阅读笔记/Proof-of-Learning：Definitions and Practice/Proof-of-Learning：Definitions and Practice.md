# Proof-of-Learning：Definitions and Practice

```
https://arxiv.org/abs/2103.05633
```

## 摘要

​	作者根据训练中的随机性，通过设置检查点，记录训练过程中的信息构建PoL。即各个检查点可以通过记录的信息训练到下一个检查点，只需在检查点进行校验。

## PoL定义

​	作者对一个有效的PoL的公式化定义如下：

![PTWIHA](PTWIHA.png)

- T表式证明者（V是验证者，未表式出）
- f_WT表示已训练的模型
- W表示训练过程中主要信息的集合（一般为权重）
- I用于获取特定位置的数据信息
- H是训练数据的哈希值
- A表示一些类似于loss函数、优化器之类的信息

## PoL属性

- G1：正确性：如果证明者通过从随机初始化的模型参数中训练模型从而获得该 PoL，直到它们收敛到 f_WT，则 f_WT 的 PoL 应该是可验证的。
- G2：安全性：如果对手A提供虚假的PoL，那么它有很高概率被检测到。
- G3：高效性：理想情况下，验证在计算上应该比生成证明计算成本更少。另外，在不同的设备上，验证理论上也能成功。
- G4：模型无关性：证明生成策略应具有通用性，适用于不同性质和复杂度的模型。
- G5：有限开销：生成证明应对已经计算成本高昂的训练过程产生有限的额外开销。
- G6：简洁证明：生成的证明数量远小于训练的步骤。

## 核心思想

- 逆推梯度下降过程（即给定最终权重和损失函数，找到之前的权重）在计算上是十分困难的，至少需要与正向训练过程相当的计算量，因此PoL难以伪造。
- 验证者通过重新执行部分选定的梯度下降步骤来验证PoL的正确性。由于逆推困难，验证者可以仅验证部分关键步骤，而无需验证整个训练过程，从而节省计算资源。

## 算法

![Algorithm1PoLCreation](Algorithm1PoLCreation.png)

![Algorithm2VerifyingaPoL](Algorithm2VerifyingaPoL.png)

​	作者说δ可以设置为训练期间几次梯度更新的平均值或者根据训练参数人为给定一个定值。

## 实验

​	作者在CIFAR-10和CIFAR-100上训练了ResNet-20和ResNet-50模型，并使用这些模型来验证PoL机制。

​	下图表示检查点间隔对证明的影响。

![Fig1Checkpoint](Fig1Checkpoint.png)

​	下图表示不同检查点间隔下的存储开销对证明的影响。

![Fig2Storage](Fig2Storage.png)

​	下图表示不同学习率对证明的影响。

![Fig3LearningRate](Fig3LearningRate.png)

## 谈谈

​	与Optimistic Verifiable Training相比，这个方法只需检查点已经允许一定的误差，效率上来说会高一点。但是很奇怪没给出允许误差范围的确定方法，只列举了几点可行的方法。

